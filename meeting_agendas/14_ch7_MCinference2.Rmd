---
title: "MONTE CARLO METHODS IN INFERENCE"
subtitle: "Chapter 7 SCR2e, Part II"
author: "AG Schissler"
date: "18 Mar 2021 (*updated: `r Sys.Date()`)*"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
---

```{r LoadLib, echo = FALSE, eval = TRUE, message=FALSE, warning=FALSE, results = "hide"}
set.seed( 03162021 )
library(tidyverse)
library(printr)
## xaringan::inf_mr('14_ch7_MCinference2.Rmd')
## str(knitr::opts_chunk$get())
```

<!-- open up etext as you go. don't typeset the chapter -->

# i. Admin & Startup

- review schedule

## Action items

### Students

- Ch. 6 HW due 19 Mar 2021.
- Ch. 7 HW due 26 Mar 2021.

### Instructor

- Grade Ch. 5 HW
- Prep meeting agendas for this week: Ch.7.
- Prep meeting agendas for next week: Ch.8.

## Any questions on Ch.6 HW?

- 6.1 (MC integration; see example 6.1,6.2)
- 6.2 (MC `pnorm`; see example 6.3)
- 6.3 (comparing MC estimators)
- 6.6, 6.7 (antithetic variates)
- 6.12 (importance sampling theory; see p.172)
- 6.13 (importance sampling; focus on the support; hint use translation)
- 6.15 (stratified importance sampling; see examples 6.11 and 6.14)

## Today's plan

i. Open with questions on Ch. 7 Problem Set to prime learning.
ii. Discuss roughly half of Ch. 7
iii. Summarize, conclude, revisit Ch. 7 Problem prompt discussion / hints time remaining

*Please contribute questions and comments*

# MC for Inference Overview

- 7.1 Introduction
- 7.2 MC Methods for Estimation
- 7.3 MC Methods for Hypothesis Testing 
- 7.4 Application: "Count Five" Test for Variance

# I. Ch.7 HW

- 7.1 Trimmed mean
- 7.3 Power of $t-test$
- 7.5 Run length encoding
- 7.6 robustness of $t-interval$
- 7.10 Gini index 
- Project 7.D. (mvn tests of normality ; see `mlbench`package)

# II. Recall 7.1 Introduction

## Example estimation tasks 

- estimate parameters of sampling distribution of a statistic
- Estimate MSE
- quantiles, probabilities, etc.

## Example inferential tasks 

- Coverage rates for confidence intervals
- Empirical Type I error rates
- Empirical Power/Type II error rates 
- Make methodological comparisons 

## Categorization of MC methods

- Ch. 7 methods draw random samples from a given model, sometimes called *parameteric* bootstrap.
- This is to constrast to the popular, nonparametric bootstrap that will be discussed in Ch. 8.
- Bootstrap is a type of a *resampling* method, whereas Ch. 7 is just sampling.

# III. 7.3 MC Methods for Hypothesis Tests

## Discuss 7.3 notation

- Any questions on the notation on p.184?

## 7.3.1 Empirical Type I Error Rate

- Discuss algorithm on p.193

## Example 7.7 (Empirical Type I error rate)

```{r 77}
n <- 20
alpha <- .05
mu0 <- 500
sigma <- 100

m <- 10000          #number of replicates
p <- numeric(m)     #storage for p-values
for (j in 1:m) {
    x <- rnorm(n, mu0, sigma)
    ttest <- t.test(x, alternative = "greater", mu = mu0)
    p[j] <- ttest$p.value
}

p.hat <- mean(p < alpha)
se.hat <- sqrt(p.hat * (1 - p.hat) / m)
print(c(p.hat, se.hat))
```

## Example 7.8 (Skewness test of normality)

```{r 78}
n <- c(10, 20, 30, 50, 100, 500) #sample sizes
cv <- qnorm(.975, 0, sqrt(6/n))  #crit. values for each n

sk <- function(x) {
    ##computes the sample skewness coeff.
    xbar <- mean(x)
    m3 <- mean((x - xbar)^3)
    m2 <- mean((x - xbar)^2)
    return( m3 / m2^1.5 )
}
p.reject <- numeric(length(n)) #to store sim. results
m <- 10000                     #num. repl. each sim.
for (i in 1:length(n)) {
    sktests <- numeric(m)       #test decisions
    for (j in 1:m) {
        x <- rnorm(n[i])
        ##test decision is 1 (reject) or 0
        sktests[j] <- as.integer(abs(sk(x)) >= cv[i] )
    }
    p.reject[i] <- mean(sktests) #proportion rejected
}
```

---

```{r 78b, warning=F}
rbind(n, p.reject)
```

## 7.3.2 Power of a Test

- Discuss algorithm on p.197


## Example 7.9 (Empirical power)

```{r 79}
n <- 20
m <- 1000
mu0 <- 500
sigma <- 100
mu <- c(seq(450, 650, 10))  #alternatives
M <- length(mu)
power <- numeric(M)
for (i in 1:M) {
    mu1 <- mu[i]
    pvalues <- replicate(m, expr = {
        ##simulate under alternative mu1
        x <- rnorm(n, mean = mu1, sd = sigma)
        ttest <- t.test(x,
                        alternative = "greater", mu = mu0)
        ttest$p.value  } )
    power[i] <- mean(pvalues <= .05)
}
    
se <- sqrt(power * (1-power) / m)
df <- data.frame(mean=mu, power=power, upper=power+2*se, lower=power-2*se)
```

## Example 7.9, Figure from the book cover

```{r 79b}
library(ggplot2)
p0 <- ggplot(df, aes(x=mean, y=power)) +
    geom_line() +
    geom_vline(xintercept=500, lty=2) +
    geom_hline(yintercept=c(0,.05), lty=1:2) +
    geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.2, lwd=1.5)
```

## Example 7.9, Figure from the book cover

```{r 79c, echo=F}
p0
```

## Discuss Remark 7.2

- Interesting comment regarding where the noncentral $t$ can arise on p.198.

## Example 7.10 (Power, skewness test of normality)

```{r 710}
alpha <- .1
n <- 30
m <- 2500
epsilon <- c(seq(0, .15, .01), seq(.15, 1, .05))
N <- length(epsilon)
pwr <- numeric(N)
##critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
```

## Example 7.10 (Power, skewness test of normality)

```{r 710b}
for (j in 1:N) {           #for each epsilon
    e <- epsilon[j]
    sktests <- numeric(m)
    for (i in 1:m) {       #for each replicate
        sigma <- sample(c(1, 10), replace = TRUE,
                        size = n, prob = c(1-e, e))
        x <- rnorm(n, 0, sigma)
        sktests[i] <- as.integer(abs(sk(x)) >= cv)
    }
    pwr[j] <- mean(sktests)
}
se <- sqrt(pwr * (1-pwr) / m)
df <- data.frame(epsilon=epsilon, power=pwr, upper=pwr+2*se, lower=pwr-2*se)
```

## Example 7.10 (Power, skewness test of normality)

```{r 710c}
##plot power vs epsilon
library(ggplot2)
p0 <- ggplot(df, aes(x=epsilon, y=power)) +
    geom_line() + labs(x=bquote(epsilon)) +
    geom_hline(yintercept=.1, lty=2) +
    geom_pointrange(aes(ymin=lower, ymax=upper))
```

## Example 7.10 (Power, skewness test of normality)

```{r 710d, echo=F}
p0
```

## 7.3.3 Power comparisons

- compare normality tests

## Example 7.11 (Compare power, normality)

```{r 711}
## initialize input and output
library(energy)
alpha <- .1
n <- 30
m <- 500        #try small m for a trial run
test1 <- test2 <- test3 <- numeric(m)
##critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
sim <- matrix(0, 11, 4)
```

## Example 7.11 (Compare power, normality)

```{r 711b, cache=T}
## estimate power
for (i in 0:10) {
    epsilon <- i * .1
    for (j in 1:m) {
        e <- epsilon
        sigma <- sample(c(1, 10), replace = TRUE,
                        size = n, prob = c(1-e, e))
        x <- rnorm(n, 0, sigma)
        test1[j] <- as.integer(abs(sk(x)) >= cv)
        test2[j] <- as.integer(
            shapiro.test(x)$p.value <= alpha)
        test3[j] <- as.integer(
            mvnorm.etest(x, R=200)$p.value <= alpha)
    }
    ## print(c(epsilon, mean(test1), mean(test2), mean(test3)))
    sim[i+1, ] <- c(epsilon, mean(test1), mean(test2), mean(test3))
}
detach(package:energy)
```

## Example 7.11 (Compare power, normality)

```{r 711b2, echo=F, warning=F}
sim
```

## Example 7.11 (Compare power, normality)

```{r 711c, echo=F}
plot(sim[,1], sim[,2], ylim = c(0, 1), type = "l",
     xlab = bquote(epsilon), ylab = "power")
lines(sim[,1], sim[,3], lty = 2)
lines(sim[,1], sim[,4], lty = 4)
abline(h = alpha, lty = 3)
legend("topright", 1, c("skewness", "S-W", "energy"),
       lty = c(1,2,4), inset = .02)
```

# Closing / Ch. 7 Problem set

- Revisit HW.
- Questions?
- Students please summarize/ask questions about what we discussed today.
- Discuss 7.4 Count Five if time remains, Example 7.12-7.16
